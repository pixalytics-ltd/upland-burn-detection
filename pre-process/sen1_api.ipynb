{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be run once to setup modules and paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "import subprocess\n",
    "import shlex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_products = products.sort_values([\"relativeorbitnumber\", \"orbitdirection\", \"slicenumber\", \"ingestiondate\"], ascending=[True, True, True, True]) #df1.sort(['a', 'b'], ascending=[True, False])\n",
    "pairs = {}\n",
    "pair_list = []\n",
    "downloadfolder = os.path.join(basefolder, \"s1slc\")\n",
    "\n",
    "import requests\n",
    "import fcntl\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def download_file(download_url, filename):\n",
    "    args = [\n",
    "            \"wget\",\n",
    "            '%s'%(download_url),\n",
    "            \"--user\",\n",
    "            \"helpdesk@pixalytics.com\",\n",
    "            \"--password\",\n",
    "            \"Pixalytics123!\",\n",
    "            \"-O\",\n",
    "            '%s.zip'%(filename),\n",
    "            ]\n",
    "\n",
    "    # create the subprocess\n",
    "    p = subprocess.Popen(args,\n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stderr=subprocess.STDOUT,\n",
    "                         bufsize=1,\n",
    "                         universal_newlines=True)\n",
    "\n",
    "    # forward messages from stdout and stderr onto the console\n",
    "    with p.stdout as stdout:\n",
    "        for line in iter(stdout.readline, b\"\"):\n",
    "            if line == \"\":\n",
    "                break\n",
    "            clear_output(wait=True)\n",
    "            print(\"Downloading %s\"%(filename), line.rstrip())\n",
    "\n",
    "    # wait to exit and retreieve the exit code\n",
    "    exit_code = p.wait()\n",
    "\n",
    "    # raise an exception if 'gpt' return an unexpected exit code\n",
    "    if exit_code != 0:\n",
    "        raise RuntimeError(\"Non-zero return code from GPT.\")\n",
    "\n",
    "def batch_download_from_archive(filtered_products, downloadfolder):\n",
    "    currently_requested = None\n",
    "    for download_num, (id1, data) in enumerate(filtered_products.iterrows()):\n",
    "        session = requests.Session()\n",
    "        session.auth = ('helpdesk@pixalytics.com', 'Pixalytics123!')\n",
    "        #print(id, data['title'])\n",
    "        print(download_num)\n",
    "        waiting_for = 0\n",
    "        while True:\n",
    "            queryurl = \"\"\"https://catalogue.onda-dias.eu/dias-catalogue/Products(%s)\"\"\"%(id1)\n",
    "            offline = session.get(queryurl)\n",
    "            offline = offline.text.split(\"offline\")[1][2:6]\n",
    "            if offline == \"true\":\n",
    "                offline = True \n",
    "            elif offline == \"fals\":\n",
    "                offline = False\n",
    "            if offline:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Downloaded %s of %s files\"%(download_num, len(filtered_data)))\n",
    "                print(\"Requested %s, id = %s\"%(data['title'], id1))\n",
    "                print(\"Waiting for %s minutes\"%(waiting_for))\n",
    "                if id1 == currently_requested:\n",
    "                    time.sleep(300)\n",
    "                    waiting_for += 5\n",
    "                else:\n",
    "                    requested = session.post(\"https://catalogue.onda-dias.eu/dias-catalogue/Products(%s)/Ens.Order\"%(id1))\n",
    "                    currently_requested = id1\n",
    "            else:\n",
    "                download_url = \"\"\"https://catalogue.onda-dias.eu/dias-catalogue/Products(%s)/$value\"\"\"%(id1)\n",
    "                download_file(download_url, os.path.join(downloadfolder, data['title']))\n",
    "                clear_output(wait=True)\n",
    "                print(\"Downloaded %s of %s files\"%(download_num, len(filtered_data)))\n",
    "                print(\"Requested %s, id = %s\"%(data['title'], id1))\n",
    "                break\n",
    "            \"\"\"\n",
    "            if requested.status_code == 429: #too many requests error\n",
    "                clear_output(wait=True)\n",
    "                print(\"Too many requests in the last hour, will try again soon for %s\"%(id))\n",
    "                time.sleep(300)\n",
    "                continue\n",
    "            requested_response = requested.json()\n",
    "            if (requested.status_code == 403) & (requested_response['error']['message'] == 'Could not order an online product'): # This error says {\"error\":{\"code\":\"001\",\"message\":\"Could not order an online product\"}} - but lets check\n",
    "                download_url = \"https://catalogue.onda-dias.eu/dias-catalogue/Products(%s)/$value\"%(id1)\n",
    "                download_file(download_url, os.path.join(downloadfolder, data['title']))\n",
    "                break\n",
    "            elif requested.status_code == 401: # if the session has ended - restart it \n",
    "                session = requests.Session()\n",
    "                session.auth = ('helpdesk@pixalytics.com', 'Pixalytics123!')\n",
    "            else:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Downloaded %s of %s files\"%(download_num, len(products)))\n",
    "                print(\"Requested %s, id = %s\"%(data['title'], id1))\n",
    "                print(requested, requested_response)\n",
    "            time.sleep(60)\n",
    "            \"\"\"\n",
    "for n, (i, p) in enumerate(sorted_products.iterrows()):\n",
    "    current_slice = p['slicenumber']\n",
    "    if n == 0:\n",
    "        last_slice = current_slice\n",
    "    if current_slice != last_slice:  \n",
    "        pairs[last_orbit, last_slice] = pair_list\n",
    "        pair_list = []\n",
    "    pair_list.append(p['title'])\n",
    "    last_slice = p['slicenumber']\n",
    "    last_orbit = p['relativeorbitnumber']\n",
    "    #print(p['polarisationmode'], p['relativeorbitnumber'], p['orbitdirection'], p['ingestiondate'], p['slicenumber'])\n",
    "\n",
    "# first set it up to download files\n",
    "#for pairings, title_list in pairs.items():\n",
    "#pairing_data = products[products['title'].isin(title_list)]\n",
    "filtered_data = check_for_existing_downloads(products, downloadfolder) \n",
    "batch_download_from_archive(filtered_data, downloadfolder)\n",
    "\"\"\"\n",
    "    ### download_files\n",
    "    products_to_download = filtered_data.index.to_list()\n",
    "    # unhash the below lines when the download folder is properly set!\n",
    "    if pairings != (23, 5):\n",
    "        continue\n",
    "    for p in products_to_download:\n",
    "        #api.download(p, directory_path=downloadfolder)\n",
    "            continue\n",
    "    \n",
    "print(os.listdir(basefolder))\n",
    "#for d, p in products.iterrows():\n",
    "#    print(p['title'], p['relativeorbitnumber'], p['orbitdirection'], p['slicenumber'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(os.path.join(basefolder, \"s1slc\")))\n",
    "#os.remove(os.path.join(basefolder, \"s1slc/S1B_IW_SLC__1SDV_20190201T064521_20190201T064548_014749_01B806_77D9.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = '/opt/snap/bin/gpt'\n",
    "# Choose the pairing and prepare the properties files...\n",
    "#file1 = os.path.join(os.getcwd(), 'temp_data/S1A_IW_SLC__1SDV_20201011T064608_20201011T064635_034745_040C5C_E064.zip')\n",
    "file1 = os.path.join(os.getcwd(), 'temp_data/S1A_IW_SLC__1SDV_20201023T064607_20201023T064634_034920_04126F_BF03.zip')\n",
    "file2 = os.path.join(os.getcwd(), 'temp_data/S1A_IW_SLC__1SDV_20201104T064607_20201104T064634_035095_041874_B5FE.zip')\n",
    "xml_folder = os.path.join(os.getcwd(), \"SLC_Data_processing/XML_files/\")\n",
    "intermediate_path = os.path.join(os.getcwd(), \"SLC_Data_processing/Intermediate_files/\")\n",
    "processed_folder =  os.path.join(os.getcwd(), \"SLC_Data_processing/Processed_images/\")\n",
    "\n",
    "outputname = os.path.basename(file1).split(\"_\")[5] + \"_\" + os.path.basename(file2).split(\"_\")[5]\n",
    "outputname = os.path.join(processed_folder, outputname+\".tif\")                  \n",
    "assert os.path.isdir(processed_folder), \"Unable to locate '{}'.\".format(processed_folder) \n",
    "\n",
    "if os.path.isfile(outputname):\n",
    "    processed_file_exists = True\n",
    "else:\n",
    "    processed_file_exists = False\n",
    "processed_file_exists = False\n",
    "# lets see if we have already processed this combination\n",
    "if not processed_file_exists:\n",
    "    # Lets do it for each swath\n",
    "    input1 = \"input1=\"+file1\n",
    "    input2 = \"input2=\"+file2\n",
    "    outputs = []\n",
    "    for swathnum in range(1, 4):\n",
    "        output = \"output=\" + intermediate_path + \"IW%s\"%(swathnum)\n",
    "        swath=\"swath=IW%s\"%(swathnum)\n",
    "        f = open(os.path.join(xml_folder, \"subswath%s.properties\"%(swathnum)), \"w\")\n",
    "        f.write(input1+\"\\n\")\n",
    "        f.write(input2+\"\\n\")\n",
    "        f.write(output+\"\\n\")\n",
    "        f.write(swath+\"\\n\")\n",
    "        f.close()\n",
    "        outputs.append(\"input%s=\"%(swathnum) + intermediate_path + \"IW%s.dim\"%(swathnum))\n",
    "    # finally lets write the Mergeswaths.properties file\n",
    "    f = open(os.path.join(xml_folder, \"Mergeswaths.properties\"), \"w\")\n",
    "    f.write(outputs[0]+\"\\n\")\n",
    "    f.write(outputs[1]+\"\\n\")\n",
    "    f.write(outputs[2]+\"\\n\")\n",
    "    f.write(\"output=\" + outputname.strip(\".tif\"))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the individual subswaths\n",
    "if not processed_file_exists:\n",
    "    xml_filename = os.path.join(xml_folder, 'ProcessSubswath.xml')\n",
    "    assert os.path.exists(gpt), \"Unable to find 'gpt' executable.\"\n",
    "    assert os.path.isfile(xml_filename), \"Unable to locate '{}'.\".format(xml_filename)\n",
    "\n",
    "    #Lets loop through and process the individual swaths\n",
    "    properties_files = [os.path.join(xml_folder, file) for file in os.listdir(xml_folder) if (file.endswith(\".properties\")) and (file.startswith(\"subswath\"))]\n",
    "    # create the subprocess\n",
    "    for propfile in properties_files:\n",
    "        print(propfile)\n",
    "        args = [\n",
    "                gpt,\n",
    "                xml_filename,\n",
    "                \"-p\",\n",
    "                propfile\n",
    "            ]\n",
    "\n",
    "        # create the subprocess\n",
    "        p = subprocess.Popen(args,\n",
    "                             stdout=subprocess.PIPE,\n",
    "                             stderr=subprocess.STDOUT,\n",
    "                             bufsize=1,\n",
    "                             universal_newlines=True)\n",
    "\n",
    "        # forward messages from stdout and stderr onto the console\n",
    "        with p.stdout as stdout:\n",
    "            for line in iter(stdout.readline, b\"\"):\n",
    "                if line == \"\":\n",
    "                    break\n",
    "                print(line.rstrip())\n",
    "\n",
    "        # wait to exit and retreieve the exit code\n",
    "        exit_code = p.wait()\n",
    "\n",
    "        # raise an exception if 'gpt' return an unexpected exit code\n",
    "        if exit_code != 0:\n",
    "            raise RuntimeError(\"Non-zero return code from GPT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the individual subswaths\n",
    "if not processed_file_exists:\n",
    "    print(\"Merging subswaths and saving to %s\"%(outputname))\n",
    "    xml_filename = os.path.join(xml_folder, 'Mergeswaths.xml')\n",
    "    propfile = os.path.join(xml_folder, 'Mergeswaths.properties')\n",
    "    args = [\n",
    "            gpt,\n",
    "            xml_filename,\n",
    "            \"-p\",\n",
    "            propfile\n",
    "        ]\n",
    "\n",
    "    # create the subprocess\n",
    "    p = subprocess.Popen(args,\n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stderr=subprocess.STDOUT,\n",
    "                         bufsize=1,\n",
    "                         universal_newlines=True)\n",
    "\n",
    "    # forward messages from stdout and stderr onto the console\n",
    "    with p.stdout as stdout:\n",
    "        for line in iter(stdout.readline, b\"\"):\n",
    "            if line == \"\":\n",
    "                break\n",
    "            print(line.rstrip())\n",
    "\n",
    "    # wait to exit and retreieve the exit code\n",
    "    exit_code = p.wait()\n",
    "\n",
    "    # raise an exception if 'gpt' return an unexpected exit code\n",
    "    if exit_code != 0:\n",
    "        raise RuntimeError(\"Non-zero return code from GPT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rsgislib_dev]",
   "language": "python",
   "name": "conda-env-rsgislib_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
