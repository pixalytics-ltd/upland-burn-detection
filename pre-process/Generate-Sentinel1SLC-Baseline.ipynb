{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be run once to setup modules and paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload modules without shutting notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Do not show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global variables including folders\n",
    "home = os.path.expanduser(\"~\")\n",
    "notebfolder = os.path.join(home, \"notebooks\")\n",
    "basefolder = os.path.join(home, \"my_shared_data_folder\")\n",
    "s1slcfolder = os.path.join(basefolder, \"s1slc\")\n",
    "datasets = os.path.join(basefolder, \"datasets\")\n",
    "baseline_dir = os.path.join(basefolder, \"baselines\")\n",
    "                           \n",
    "# Upland burn modules\n",
    "import sys\n",
    "sys.path.append(os.path.join(notebfolder, \"utils\"))\n",
    "from baseline_estimate import *\n",
    "\n",
    "## setup temp folder\n",
    "tmpfolder = os.path.join(notebfolder, \"temp\")\n",
    "if not os.path.exists(tmpfolder):\n",
    "    os.mkdir(tmpfolder)\n",
    "tmptiffolder = os.path.join(tmpfolder, \"tiffs\")\n",
    "if not os.path.exists(tmptiffolder):\n",
    "    os.mkdir(tmptiffolder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing SLC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file = os.path.join(tmpfolder, \"vector_data_%s.p\"%(cstudy))\n",
    "if os.path.exists(vector_file):\n",
    "    vector_data = pickle.load(open(vector_file, \"rb\"))    \n",
    "    print(\"Loading {} vectors from {}\".format(len(vector_data), vector_file))  \n",
    "else:    \n",
    "    print(\"{} doesn't exist, Creating new vector data\".format(vector_file))  \n",
    "    vector_data = None\n",
    "\n",
    "print(\"Getting vector data\")\n",
    "vector_data = get_vector_data(products, vector_data=vector_data)\n",
    "if os.path.exists(vector_file):\n",
    "    os.remove(vector_file)\n",
    "pickle.dump(vector_data, open(vector_file, \"wb\"))\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Saved {} vectors to {}\".format(len(vector_data), vector_file))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings_baselines = {}\n",
    "total_done = 0\n",
    "for p in list_of_potential_pairs:\n",
    "    file1 = os.path.join(s1slcfolder, p[0])\n",
    "    file2 = os.path.join(s1slcfolder, p[1])\n",
    "    total_done +=1\n",
    "    t1 = vector_data[os.path.basename(file1).strip(\".zip\")]\n",
    "    t2 = vector_data[os.path.basename(file2).strip(\".zip\")]\n",
    "    dist = closestDistanceBetweenLines(np.array(t1[0]), np.array(t1[-1]), np.array(t2[0]), np.array(t2[-1]))\n",
    "    pairings_baselines[p[0], p[1]] = dist\n",
    "    print(p[0], p[1], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1slc_analysed_folder = os.path.join(tmpfolder, 'Processed_images/')\n",
    "if not os.path.exists(s1slc_analysed_folder):\n",
    "    os.mkdir(s1slc_analysed_folder)\n",
    "final_folder = os.path.join(basefolder, \"%s/coherence_tiffs\"%(cstudy))\n",
    "assert os.path.exists(final_folder), \"Final folder %s doesnt exist\"%(final_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the baseline files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_merge_dict = {}\n",
    "baseline_dict = {}\n",
    "                \n",
    "for p in list_of_potential_pairs:\n",
    "    file1 = os.path.basename(p[0]).split(\"_\")[-5]\n",
    "    file2 = os.path.basename(p[1]).split(\"_\")[-5]\n",
    "    basename = os.path.basename(p[0]).strip(\".zip\")\n",
    "    sensor = file1[2] + file2[2]\n",
    "    for pol in [\"VH\", \"VV\"]:\n",
    "        outfile = file1 + \"_\" + file2 + \"_%s.tif\"%(pol)\n",
    "        orbit_direction = products[products['title'] == basename]['orbitdirection'][0]\n",
    "        num = products[products['title'] == basename]['relativeorbitnumber'][0]\n",
    "        merge_id = (num, sensor, outfile[:8], outfile.split(\"_\")[1][:8], orbit_direction, pol)\n",
    "        if not merge_id in file_merge_dict.keys():\n",
    "            file_merge_dict[merge_id] = [outfile]\n",
    "            baseline_dict[merge_id] = [pairings_baselines[p[0], p[1]]]\n",
    "            continue\n",
    "        file_merge_dict[merge_id].append(outfile)\n",
    "        baseline_dict[merge_id].append(pairings_baselines[p[0], p[1]])\n",
    "            \n",
    "baseline_file = os.path.join(baseline_dir, \"baselines_%s.p\"%(cstudy))\n",
    "if os.path.exists(baseline_file):  \n",
    "    baseline_perp_dict = pickle.load(open(baseline_file, \"rb\"))\n",
    "    print(\"Loading {} from {}\".format(len(baseline_perp_dict), baseline_file))  \n",
    "else:\n",
    "    print(\"Creating new baseline file\")  \n",
    "    baseline_perp_dict = {}\n",
    "    \n",
    "for id1, files in file_merge_dict.items():\n",
    "    outfile = \"%s_%s_%s_%s_%s_%s_%s\"%(id1[0], id1[1], id1[2], id1[3], id1[4], id1[5], cstudy)\n",
    "    outfile_tif = os.path.join(final_folder, '%s.tif'%(outfile))\n",
    "    baseline = np.mean(baseline_dict[id1])\n",
    "    if outfile_tif in baseline_perp_dict.keys():\n",
    "        continue\n",
    "    baseline_perp_dict[outfile_tif] = baseline\n",
    "    \n",
    "pickle.dump(baseline_perp_dict, open(baseline_file, \"wb\"))\n",
    "                               \n",
    "#clear_output(wait=True)\n",
    "print(\"Saved {} baselines to {}\".format(len(baseline_perp_dict), baseline_file))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rsgislib_dev]",
   "language": "python",
   "name": "conda-env-rsgislib_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
