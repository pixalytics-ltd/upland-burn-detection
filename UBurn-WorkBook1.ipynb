{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loaded configuration: {'sharedfolder': 'my_shared_data_folder'}.\n",
      "Check:  /home/slavender/my_shared_data_folder/skye/S1B_20190201_30_asc_175839_175904_VVVH_G0_GB_OSGB_RTCK_SpkRL.tif\n"
     ]
    }
   ],
   "source": [
    "#Reload modules without shutting notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from utils.get_configuration import get_configuration\n",
    "\n",
    "# Get configuration information\n",
    "cstudy = \"skye\" \n",
    "#cstudy = \"cairngorms\" \n",
    "#cstudy = \"pdistrict\" \n",
    "\n",
    "basefolder, s1ardfolder, datasets, outfolder, tmpfolder, ofiles, hdfile, pfile, verbose, graphics = get_configuration(cstudy)\n",
    "if cstudy == \"skye\":\n",
    "    aoi = os.path.join(datasets, \"Skye_extent_OSGB36.geojson\")\n",
    "elif cstudy == \"cairngorms\":\n",
    "    aoi = os.path.join(datasets, \"Cairngorms_extent_OSGB36.geojson\")    \n",
    "else:\n",
    "    aoi = os.path.join(datasets, \"PDistrict_extent_OSGB36.geojson\")\n",
    "fstart = os.path.basename(aoi).split(\"_\")[0]\n",
    "subarray = None\n",
    "print(\"Check: \",ofiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose skye burn area\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9acb45c7214043ae5b2142cb415f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Polygon:', options=('006', '009', '016', '026', '054', '110', '143', '153', '156', '160'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose Burn Polygon\n",
    "from ipywidgets import Dropdown\n",
    "\n",
    "searchstr = fstart + \"_burn_extent_*.geojson\"\n",
    "polygons = glob.glob(os.path.join(datasets, searchstr))\n",
    "if len(polygons) == 0:\n",
    "    print(\"No polygons exist for {}\".format(searchstr))\n",
    "poly_list = []\n",
    "for poly in polygons:\n",
    "    fpoly = os.path.splitext(os.path.basename(poly))[0]\n",
    "    poly_list.append(fpoly.split(\"_\")[3])\n",
    "\n",
    "# Convert string list to int list, sort then convert back\n",
    "poly_int = [int(i) for i in poly_list]\n",
    "poly_int.sort()\n",
    "poly_list = [str(i).zfill(3) for i in poly_int]\n",
    "del poly_int\n",
    "\n",
    "b_widget = Dropdown(options = poly_list, description = \"Polygon:\", value = poly_list[0])\n",
    "def change_x(*args):\n",
    "    print(\"Set to {}\".format(b_widget.value))\n",
    "    \n",
    "b_widget.observe(change_x, 'value')\n",
    "print(\"Choose {} burn area\".format(cstudy))\n",
    "display(b_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen polygon: Skye_burn_extent_326\n",
      "Baseline non-burn polygon available\n"
     ]
    }
   ],
   "source": [
    "# Set polygon from drop-down above\n",
    "endstr = \".geojson\"\n",
    "burn = \"Skye_burn_extent_\" + b_widget.value\n",
    "baseline = \"Skye_baseline_extent_\" + b_widget.value\n",
    "if os.path.exists(os.path.join(datasets, burn + endstr)):\n",
    "    print(\"Chosen polygon: {}\".format(burn))\n",
    "    if os.path.exists(os.path.join(datasets, baseline + endstr)):\n",
    "        print(\"Baseline non-burn polygon available\")\n",
    "        bdata = True\n",
    "    else:\n",
    "        print(\"No baseline data available\")\n",
    "        bdata = False\n",
    "else:\n",
    "    print(\"ERROR: chosen polygon {} not found\".format(burn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dataset from: /home/slavender/my_shared_data_folder\n",
      "Already downloaded: /home/slavender/temp/Skye_burn_extent_326-download.nc \n",
      "Loading: odict_keys(['longitude', 'latitude', 'time', 'u10', 'v10', 'lai_hv', 'lai_lv', 'snowc', 'sp', 'sro', 'ssrd', 'tp'])  \n",
      "Extracted data shape:  (365, 9)\n",
      "Input dataset from: /home/slavender/my_shared_data_folder\n",
      "Already downloaded: /home/slavender/temp/Skye_baseline_extent_326-download.nc \n",
      "Loading: odict_keys(['longitude', 'latitude', 'time', 'u10', 'v10', 'lai_hv', 'lai_lv', 'snowc', 'sp', 'sro', 'ssrd', 'tp'])  \n",
      "Extracted data shape:  (365, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load ERA5Land data\n",
    "graphics = False # do not display graphs\n",
    "polygon = burn\n",
    "%run ./Pull-ERA5.ipynb $polygon $verbose $graphics\n",
    "if bdata:  # run for baseline polygon:\n",
    "    polygon = baseline\n",
    "    %run ./Pull-ERA5.ipynb $polygon $verbose $graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Input dataset from: /home/slavender/my_shared_data_folder\n",
      "Loading layer 44 of 44\n",
      " Extracting only polygon area...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e80fe36dc4d483a8eede2aea564b752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='polarisation', options=('VV', 'VH'), value='VV'), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec8c89757994f94b6d182ef2c009ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Save', style=ButtonStyle()), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Sentinel-1 ARD backscatter data for burn extent polygon\n",
    "subarray = None # So runs again - ToDo to update so if run for same polygon does not reload\n",
    "polygon = burn\n",
    "%run ./Analyse-Sentinel1.ipynb $polygon $verbose\n",
    "burn_subarray = subarray\n",
    "burn_df = df\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Input dataset from: /home/slavender/my_shared_data_folder\n",
      "Loading layer 44 of 44\n",
      " Extracting only polygon area...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73daf2f5dcda4e40af45153efee5aa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='polarisation', options=('VV', 'VH'), value='VV'), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a45e5f1a554375b5dea4e1f5ad77e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Save', style=ButtonStyle()), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Sentinel-1 ARD backscatter data for baseline polygon\n",
    "subarray = None # So runs again - ToDo to update so if run for same polygon does not reload\n",
    "if bdata:\n",
    "    polygon = baseline\n",
    "    %run ./Analyse-Sentinel1.ipynb $polygon $verbose\n",
    "    baseline_subarray = subarray\n",
    "    baseline_df = df\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel-1 ARD backscatter files in array of shape (37, 2, 124, 132) with 37 files in dataframe\n",
      "Baseline ARD in array of shape (37, 2, 71, 106) with 37 files in dataframe\n",
      "ERA5 data:  ['20190101', '20190102', '20190103', '20190104', '20190105'] (365, 9)\n"
     ]
    }
   ],
   "source": [
    "# Check ERA5 and Sentinel-1 ARD data is loaded\n",
    "print(\"Sentinel-1 ARD backscatter files in array of shape {} with {} files in dataframe\".format(burn_subarray.shape,len(burn_df)))\n",
    "if bdata:\n",
    "    print(\"Baseline ARD in array of shape {} with {} files in dataframe\".format(baseline_subarray.shape,len(baseline_df)))\n",
    "print(\"ERA5 data: \", dt_num[0:5], mean_parameters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['layer', 'sensor', 'date', 'stime', 'etime', 'polarisation', 'rorbit', 'direction']\n",
      "Choose filtering option\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a872b9d9dc4a4a8f01aceb2866d591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Options:', options=('All', 'date', 'direction', 'rorbit', 'sensor', 'stime'), value='All…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose filtering option\n",
    "filter_list = []\n",
    "headers = list(burn_df.head(0))\n",
    "print(\"Headers: {}\".format(headers))\n",
    "for col in range(len(headers)):\n",
    "    if col == 0:\n",
    "        filter_list.append('All')\n",
    "    elif headers[col] == 'etime' or headers[col] == 'polarisation':\n",
    "        continue\n",
    "    else:\n",
    "        filter_list.append(headers[col])\n",
    "\n",
    "# Sort alphabetically\n",
    "filter_list.sort()\n",
    "        \n",
    "d_widget = Dropdown(options = filter_list, description = \"Options:\", value = filter_list[0])\n",
    "def change_x(*args):\n",
    "    print(\"Set to {}\".format(d_widget.value))\n",
    "    \n",
    "d_widget.observe(change_x, 'value')\n",
    "print(\"Choose filtering option\")\n",
    "display(d_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose sub-filtering option\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558c3206062f43f19a87f3dbe21b1bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Sub Options:', options=('asc', 'desc'), value='asc')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Undertake sub-filtering based on option chosen above\n",
    "if d_widget.value == 'All':\n",
    "    print(\"Using all the data\")\n",
    "    options = ['All']\n",
    "else:\n",
    "    options = burn_df[d_widget.value].unique()\n",
    "    #print(options)\n",
    "\n",
    "# Sort alphabetically\n",
    "options.sort()\n",
    "        \n",
    "sub_widget = Dropdown(options = options, description = \"Sub Options:\", value = options[0])\n",
    "def change_x(*args):\n",
    "    print(\"Set to {}\".format(sub_widget.value))\n",
    "    \n",
    "sub_widget.observe(change_x, 'value')\n",
    "if d_widget.value != 'All':\n",
    "    print(\"Choose sub-filtering option\")\n",
    "    display(sub_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting to direction = asc\n",
      "Original (37, 2, 124, 132) subsetted to 18 layers\n",
      "Subsetting to direction = asc\n",
      "Original (37, 2, 71, 106) subsetted to 18 layers\n"
     ]
    }
   ],
   "source": [
    "# Filter the S1ARD data\n",
    "from utils.subset_s1ard import subset_s1ard\n",
    "\n",
    "filtered_burndf, filtered_burnarray, filtered_dates_burn = subset_s1ard(burn_df, burn_subarray, d_widget.value, sub_widget.value, verb = verbose)\n",
    "if bdata:\n",
    "    filtered_basedf, filtered_basearray, filtered_dates_base = subset_s1ard(baseline_df, baseline_subarray, d_widget.value, sub_widget.value, verb = verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open Collection '/home/slavender/my_shared_data_folder/datasets/u2018_clc2018_v2020_20u1_geoPackage/DATA/U2018_CLC2018_V2020_20u1.gpkg:U2018_CLC2018_V2020_20u1', mode 'r' at 0x7fac6bbb0a20>\n",
      "Extracted 2 polygons\n"
     ]
    }
   ],
   "source": [
    "# Load CORINE land cover for polygon burn area subset\n",
    "from utils.load_corine import subset_corine\n",
    "cpolygons, legend_df = subset_corine(xymin[0], xymin[1], xymax[0], xymax[1], pixelWidth, pixelHeight, datasets, verb = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 S1 dates: ['20190202' '20190205' '20190207' '20190301' '20190302'] ...\n",
      "S1ARD array (2, 6, 18)\n",
      "   Burn Moors and heathland max VV nan max VH nan VHrVV nan RFDI nan NVHI nan NVVI nan\n",
      "  Baseline Moors and heathland max VV -10.753 max VH -18.408 VHrVV 2.003 RFDI -0.160 NVHI 0.667 NVVI 0.420\n",
      "   Burn Peat bogs max VV -8.246 max VH -15.993 VHrVV 2.195 RFDI -0.247 NVHI 0.681 NVVI 0.376\n",
      "  Baseline Peat bogs max VV -10.486 max VH -17.030 VHrVV 1.789 RFDI -0.194 NVHI 0.638 NVVI 0.403\n",
      "ERA5 Precip: 18 values max 0.035\n"
     ]
    }
   ],
   "source": [
    "from utils.extract_s1ard import extract_s1ard\n",
    "from utils.calc_era_api import calc_era_api\n",
    "\n",
    "# Extract subsets of burn area using CORINE polygons\n",
    "mean_s1burn, std_s1burn, pnames, features = extract_s1ard(cpolygons, filtered_burnarray, verb = verbose)\n",
    "if bdata:\n",
    "    mean_s1base, std_s1base, pnames, features = extract_s1ard(cpolygons, filtered_basearray, verb = verbose)\n",
    "    \n",
    "# Extract ERA5 data for matching dates and calculate Antecedent Precipitation Index\n",
    "if d_widget.value == 'All':\n",
    "    filtered_dates = burn_df['date'].values\n",
    "else:\n",
    "    filtered_dates = burn_df['date'].values[filtered_dates_burn]\n",
    "mean_edata, std_edata = calc_era_api(dt_num, mean_parameters, filtered_burnarray, filtered_dates, verb = True)\n",
    "filtered_edata = filtered_dates\n",
    "eraname = 'Antecedent Precipitation Index'\n",
    "\n",
    "# Print initial arrays\n",
    "print(\"{} S1 dates: {} ...\".format(len(list_of_dates),list_of_dates[0:5]))\n",
    "print(\"S1ARD array {}\".format(mean_s1burn.shape))\n",
    "for fnum in range(len(features)):\n",
    "    print(\"   Burn {} max VV {:.3f} max VH {:.3f} VHrVV {:.3f} RFDI {:.3f} NVHI {:.3f} NVVI {:.3f}\"\n",
    "        .format(features[fnum],np.nanmax(mean_s1burn[fnum,0,:]),np.nanmax(mean_s1burn[fnum,1,:]),np.nanmax(mean_s1burn[fnum,2,:]),\n",
    "        np.nanmax(mean_s1burn[fnum,3,:]),np.nanmax(mean_s1burn[fnum,4,:]),np.nanmax(mean_s1burn[fnum,5,:])))\n",
    "    if bdata:\n",
    "        print(\"  Baseline {} max VV {:.3f} max VH {:.3f} VHrVV {:.3f} RFDI {:.3f} NVHI {:.3f} NVVI {:.3f}\"\n",
    "            .format(features[fnum],np.nanmax(mean_s1base[fnum,0,:]),np.nanmax(mean_s1base[fnum,1,:]),np.nanmax(mean_s1base[fnum,2,:]),\n",
    "            np.nanmax(mean_s1base[fnum,3,:]),np.nanmax(mean_s1base[fnum,4,:]),np.nanmax(mean_s1base[fnum,5,:])))\n",
    "print(\"ERA5 Precip: {} values max {:.3f}\".format(len(mean_edata), np.nanmax(mean_edata)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: direction using asc\n",
      "Running for 2 features with 6 products\n",
      "Generated: /home/slavender/output_folder/plot-s1ard-era-baseline.png\n",
      "Running for 2 features with 6 products\n",
      "Generated: /home/slavender/output_folder/plot-s1ard-era-burn.png\n"
     ]
    }
   ],
   "source": [
    "# Create plots for ERA5 data in comparison to Sentinel-1 ARD dates for each CORINE polygon\n",
    "plt.set_loglevel(\"critical\")\n",
    "\n",
    "if d_widget.value != \"All\":\n",
    "    print(\"Filtering: {} using {}\".format(d_widget.value, sub_widget.value))\n",
    "    \n",
    "if bdata:\n",
    "    outbase = os.path.join(outfolder,\"plot-s1ard-era-baseline.png\")\n",
    "    if d_widget.value != \"All\":\n",
    "        filtered_dates = baseline_df['date'].values[filtered_dates_base]\n",
    "    else:\n",
    "        filtered_dates = baseline_df['date'].values\n",
    "    #print(filtered_edata.shape, mean_edata.shape, std_edata.shape)\n",
    "    #print(filtered_dates.shape, mean_s1base.shape, std_s1base.shape)\n",
    "    plotd.plot_lines(filtered_dates, mean_s1base, std_s1base, filtered_edata, mean_edata, std_edata, features, pnames, eraname, outbase, graphics = False)\n",
    "    print(\"Generated: {}\".format(outbase))\n",
    "\n",
    "    outburn = os.path.join(outfolder,\"plot-s1ard-era-burn.png\")\n",
    "    if d_widget.value != \"All\":\n",
    "        filtered_dates = burn_df['date'].values[filtered_dates_burn]\n",
    "    else:\n",
    "        filtered_dates = burn_df['date'].values\n",
    "    #print(filtered_edata.shape, mean_edata.shape, std_edata.shape)\n",
    "    #print(filtered_dates.shape, mean_s1burn.shape, std_s1burn.shape)\n",
    "    plotd.plot_lines(filtered_dates, mean_s1burn, std_s1burn, filtered_edata, mean_edata, std_edata, features, pnames, eraname, outbase, graphics = False)\n",
    "    print(\"Generated: {}\".format(outburn))\n",
    "    \n",
    "else:    \n",
    "    outfile = os.path.join(outfolder,\"plot-s1ard-era-burn.png\")\n",
    "    #print(len(filtered_dates), mean_s1burn.shape, std_s1burn.shape, mean_edata.shape, std_edata.shape, len(features), len(pnames))\n",
    "    plotd.plot_lines(filtered_dates, mean_s1burn, std_s1burn, filtered_edata, mean_edata, std_edata, features, pnames, eraname, outfile, graphics = False)\n",
    "    print(\"Generated: {}\".format(outburn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b322d0aede34a029afc0242bd4396fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='Baseline polygon'), Text(value='Plotting 326 for direction data filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display plots side by side if have both baseline and burn data extracted\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# read plot images\n",
    "if bdata:\n",
    "    img1 = open(outbase, 'rb').read()\n",
    "    img2 = open(outburn, 'rb').read()\n",
    "\n",
    "    # Text widgets\n",
    "    t1 = widgets.Text(value='Baseline polygon')\n",
    "    if d_widget.value == 'All':\n",
    "        t2 = widgets.Text(value=' Plotting all available data for ' + b_widget.value)\n",
    "    else:\n",
    "        t2 = widgets.Text(value='Plotting ' + b_widget.value + ' for ' + d_widget.value + ' data filtered by ' + sub_widget.value)\n",
    "    t3 = widgets.Text(value='Burn polygon')\n",
    "    ## Create image widgets.\n",
    "    i1 = widgets.Image(value=img1, width='50%')\n",
    "    i2 = widgets.Image(value=img2, width='50%')\n",
    "    ## Side by side thanks to HBox widget\n",
    "    titles = widgets.HBox([t1, t2, t3], width='100%')\n",
    "    plots = widgets.HBox([i1, i2], width='100%')\n",
    "    ui = widgets.VBox([titles,plots])\n",
    "    ## Finally, show.\n",
    "    display(ui)\n",
    "\n",
    "else:\n",
    "    img2 = open(outburn, 'rb').read()\n",
    "\n",
    "    # display images\n",
    "    display(widgets.Image(value=img2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rsgislib_dev]",
   "language": "python",
   "name": "conda-env-rsgislib_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
